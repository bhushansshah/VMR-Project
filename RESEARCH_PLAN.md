# üé¨ Video Moment Retrieval Reading Plan

A chronological and thematic list of key papers to guide your journey in the video moment retrieval (aka temporal sentence grounding) domain.

---

## 1. Surveys & Overviews

- [Temporal Sentence Grounding in Videos: A Survey and Future Directions (Zhang et al., 2022)](https://arxiv.org/abs/2201.08858)
- [A Survey on Temporal Sentence Grounding in Videos (Lan et al., 2021)](https://arxiv.org/abs/2106.11664)

---

## 2. Core Fully-Supervised Methods

- [TALL: Temporal Activity Localization via Language Query (Gao et al., ICCV 2017)](https://openaccess.thecvf.com/content_iccv_2017/html/Gao_TALL_Temporal_Activity_ICCV_2017_paper.html)
- [Hierarchical Visual-Textual Graph for Temporal Activity Localization via Language (Chen & Jiang, ECCV 2020)](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460190.pdf)

---

## 3. Weak & Semi-Supervised Approaches

- [2D Temporal Adjacent Networks (2DTAN) for Temporal Sentence Localization (2020)](https://arxiv.org/abs/2001.06880)
- [Weakly-Supervised Video Moment Retrieval with Language-Prompted Semantic Completion (2020)](https://arxiv.org/abs/2002.03765)
- [CBP: Contextual Boundary-aware Prediction for Temporal Action Localization (AAAI 2020)](https://ojs.aaai.org/index.php/AAAI/article/view/6813)
- [Glance and Focus: A Glance Annotation Framework for Weakly Supervised Temporal Sentence Grounding (2022)](https://arxiv.org/abs/2201.07378)

---

## 4. Corpus-Level Retrieval

- [CONQUER: Efficient Video Corpus Moment Retrieval (2021)](https://dl.acm.org/doi/10.1145/3474085.3475512)
- [Video Corpus Moment Retrieval with Contrastive Learning (VCMR) (2021)](https://arxiv.org/abs/2101.00542)

---

## 5. Transformer-Based & Pretraining Methods

- [HLGT: Hierarchical Local-Global Temporal Transformer for Video-Text Retrieval (2022)](https://arxiv.org/abs/2201.05991)
- [LA-DETR: Moment Retrieval with Latent Alignment and Detection Transformer (2023)](https://arxiv.org/abs/2305.00280)
- [Keyword-DETR: Video Moment Retrieval with Keyword-aware Deformable DETR (2023)](https://arxiv.org/abs/2303.14171)

---

## üìñ Suggested Reading Order

1. **Surveys**: 2021 ‚Üí 2022 to build foundational knowledge
2. **TALL (2017)**: Understand early problem formulation and datasets
3. **HVTG (2020)**: Deepen with graph-based modeling
4. **Weakly-supervised**: Learn annotation-efficient approaches
5. **Corpus-level retrieval**: Explore scalability to large corpora
6. **Transformer-based**: Study recent SOTA methods

---

## üõ†Ô∏è Notes

- Most datasets mentioned include TACoS, Charades-STA, ActivityNet Captions, and DiDeMo.
- Look for GitHub links associated with these papers for code implementations and hands-on learning.
